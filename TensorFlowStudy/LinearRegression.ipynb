{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: MacOSX\n",
      "Epoch: 0050 cost= 0.470600247 W= 0.60019284 b= -1.7207205\n",
      "Epoch: 0100 cost= 0.425143093 W= 0.5793408 b= -1.5707124\n",
      "Epoch: 0150 cost= 0.384934455 W= 0.55972934 b= -1.4296274\n",
      "Epoch: 0200 cost= 0.349367797 W= 0.54128385 b= -1.2969325\n",
      "Epoch: 0250 cost= 0.317907661 W= 0.5239354 b= -1.1721301\n",
      "Epoch: 0300 cost= 0.290080130 W= 0.50761926 b= -1.0547515\n",
      "Epoch: 0350 cost= 0.265465379 W= 0.49227315 b= -0.94435275\n",
      "Epoch: 0400 cost= 0.243692815 W= 0.47783986 b= -0.8405207\n",
      "Epoch: 0450 cost= 0.224434212 W= 0.4642648 b= -0.7428634\n",
      "Epoch: 0500 cost= 0.207399458 W= 0.45149732 b= -0.6510147\n",
      "Epoch: 0550 cost= 0.192331955 W= 0.43948925 b= -0.5646294\n",
      "Epoch: 0600 cost= 0.179004431 W= 0.42819536 b= -0.48338175\n",
      "Epoch: 0650 cost= 0.167215914 W= 0.4175731 b= -0.40696576\n",
      "Epoch: 0700 cost= 0.156788811 W= 0.4075825 b= -0.33509472\n",
      "Epoch: 0750 cost= 0.147565961 W= 0.3981862 b= -0.267498\n",
      "Epoch: 0800 cost= 0.139408305 W= 0.3893486 b= -0.20392148\n",
      "Epoch: 0850 cost= 0.132192850 W= 0.3810368 b= -0.14412613\n",
      "Epoch: 0900 cost= 0.125810891 W= 0.3732192 b= -0.08788733\n",
      "Epoch: 0950 cost= 0.120166145 W= 0.3658666 b= -0.034993276\n",
      "Epoch: 1000 cost= 0.115173452 W= 0.35895127 b= 0.01475498\n",
      "Optimization Finished!\n",
      "Training cost= 0.11517345 W= 0.35895127 b= 0.01475498 \n",
      "\n",
      "Testing... (Mean square loss Comparison)\n",
      "Testing cost= 0.09994273\n",
      "Absolute mean square loss difference: 0.015230723\n"
     ]
    }
   ],
   "source": [
    "%matplotlib\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "rng = numpy.random\n",
    "\n",
    "# Parameters\n",
    "learning_rate = 0.01\n",
    "training_epochs = 1000\n",
    "display_step = 50\n",
    "\n",
    "# Training Data\n",
    "train_X = numpy.asarray([3.3,4.4,5.5,6.71,6.93,4.168,9.779,6.182,7.59,2.167,\n",
    "                         7.042,10.791,5.313,7.997,5.654,9.27,3.1])\n",
    "train_Y = numpy.asarray([1.7,2.76,2.09,3.19,1.694,1.573,3.366,2.596,2.53,1.221,\n",
    "                         2.827,3.465,1.65,2.904,2.42,2.94,1.3])\n",
    "n_samples = train_X.shape[0]\n",
    "\n",
    "# tf Graph Input\n",
    "X = tf.placeholder(\"float\")\n",
    "Y = tf.placeholder(\"float\")\n",
    "\n",
    "# Set model weights\n",
    "W = tf.Variable(rng.randn(), name=\"weight\")\n",
    "b = tf.Variable(rng.randn(), name=\"bias\")\n",
    "\n",
    "# Construct a linear model\n",
    "pred = tf.add(tf.multiply(X, W), b)\n",
    "\n",
    "# Mean squared error\n",
    "cost = tf.reduce_sum(tf.pow(pred-Y, 2))/(2*n_samples)\n",
    "# Gradient descent\n",
    "#  Note, minimize() knows to modify W and b because Variable objects are trainable=True by default\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "# Initialize the variables (i.e. assign their default value)\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Start training\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    # Run the initializer\n",
    "    sess.run(init)\n",
    "\n",
    "    # Fit all training data\n",
    "    for epoch in range(training_epochs):\n",
    "        for (x, y) in zip(train_X, train_Y):\n",
    "            sess.run(optimizer, feed_dict={X: x, Y: y})\n",
    "\n",
    "        # Display logs per epoch step\n",
    "        if (epoch+1) % display_step == 0:\n",
    "            c = sess.run(cost, feed_dict={X: train_X, Y:train_Y})\n",
    "            print(\"Epoch:\", '%04d' % (epoch+1), \"cost=\", \"{:.9f}\".format(c), \\\n",
    "                \"W=\", sess.run(W), \"b=\", sess.run(b))\n",
    "\n",
    "    print(\"Optimization Finished!\")\n",
    "    training_cost = sess.run(cost, feed_dict={X: train_X, Y: train_Y})\n",
    "    print(\"Training cost=\", training_cost, \"W=\", sess.run(W), \"b=\", sess.run(b), '\\n')\n",
    "\n",
    "    # Graphic display\n",
    "    plt.plot(train_X, train_Y, 'ro', label='Original data')\n",
    "    plt.plot(train_X, sess.run(W) * train_X + sess.run(b), label='Fitted line')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    # Testing example, as requested (Issue #2)\n",
    "    test_X = numpy.asarray([6.83, 4.668, 8.9, 7.91, 5.7, 8.7, 3.1, 2.1])\n",
    "    test_Y = numpy.asarray([1.84, 2.273, 3.2, 2.831, 2.92, 3.24, 1.35, 1.03])\n",
    "\n",
    "    print(\"Testing... (Mean square loss Comparison)\")\n",
    "    testing_cost = sess.run(\n",
    "        tf.reduce_sum(tf.pow(pred - Y, 2)) / (2 * test_X.shape[0]),\n",
    "        feed_dict={X: test_X, Y: test_Y})  # same function as cost above\n",
    "    print(\"Testing cost=\", testing_cost)\n",
    "    print(\"Absolute mean square loss difference:\", abs(\n",
    "        training_cost - testing_cost))\n",
    "\n",
    "    plt.plot(test_X, test_Y, 'bo', label='Testing data')\n",
    "    plt.plot(train_X, sess.run(W) * train_X + sess.run(b), label='Fitted line')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
